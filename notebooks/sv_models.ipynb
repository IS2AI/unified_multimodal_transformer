{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/Speaker_Verification_version_1.0/Speaker-Verification\n"
     ]
    }
   ],
   "source": [
    "cd /workdir/Speaker_Verification_version_1.0/Speaker-Verification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speaker_verification import transforms as T\n",
    "from speaker_verification.dataset import SpeakingFacesDataset\n",
    "from speaker_verification.dataset import ValidDataset\n",
    "from speaker_verification.sampler import ProtoSampler\n",
    "from speaker_verification.sampler import ValidSampler\n",
    "from speaker_verification.models_handmade.resnet import ResNet34\n",
    "from speaker_verification.models import ResNet\n",
    "from speaker_verification.loss import PrototypicalLoss\n",
    "from speaker_verification.train import train_model\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from speaker_verification.utils import plot_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet1 (Resnet from Pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unfrozen parameters with fine_tune=True: 21350336/21350336 - 100.0 %\n",
      "Number of frozen parameters with fine_tune=True: 0/21350336 - 0.0 %\n",
      "Total number of parameters with fine_tune=True: 21350336\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = ResNet(pretrained_weights=True, \n",
    "                        fine_tune=False, \n",
    "                        embedding_size=128, \n",
    "                        modality = \"rgb\", \n",
    "                        filter_size=\"default\", \n",
    "                        from_torch=True\n",
    "                    )\n",
    "model = model.to(device)\n",
    "\n",
    "unfrozen = 0\n",
    "frozen = 0\n",
    "total = 0\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad:\n",
    "        unfrozen += param.numel()\n",
    "    else:\n",
    "        frozen += param.numel()\n",
    "    total += param.numel()\n",
    "\n",
    "print(f\"Number of unfrozen parameters with fine_tune=True: {unfrozen}/{total} - {unfrozen/total * 100} %\")\n",
    "print(f\"Number of frozen parameters with fine_tune=True: {frozen}/{total} - {frozen / total * 100} %\")\n",
    "print(f\"Total number of parameters with fine_tune=True: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if number of parameters changes with changing to fine tune or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unfrozen parameters with fine_tune=False: 65664/21350336 - 0.307554878761627 %\n",
      "Number of frozen parameters with fine_tune=False: 21284672/21350336 - 99.69244512123836 %\n",
      "Total number of parameters with fine_tune=False: 21350336\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = ResNet(pretrained_weights=True, \n",
    "                        fine_tune=False, \n",
    "                        embedding_size=128, \n",
    "                        modality = \"rgb\", \n",
    "                        filter_size=\"default\", \n",
    "                        from_torch=True\n",
    "                    )\n",
    "model = model.to(device)\n",
    "\n",
    "unfrozen = 0\n",
    "frozen = 0\n",
    "total = 0\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad:\n",
    "        unfrozen += param.numel()\n",
    "    else:\n",
    "        frozen += param.numel()\n",
    "    total += param.numel()\n",
    "\n",
    "print(f\"Number of unfrozen parameters with fine_tune=False: {unfrozen}/{total} - {unfrozen/total * 100} %\")\n",
    "print(f\"Number of frozen parameters with fine_tune=False: {frozen}/{total} - {frozen / total * 100} %\")\n",
    "print(f\"Total number of parameters with fine_tune=False: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average train loss: 4.09436205625534\n",
      "Average train accuracy: 1.5500000739097595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval (epoch = 0): 100%|██████████| 594/594 [01:17<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average val eer: 48.8092462548469\n",
      "\n",
      "Average val accuracy: 50.56642817059483\n",
      "Best eer model saved at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [01:48<00:00, 108.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best acc model saved at epoch 0\n",
      "Time elapsed: 1.800370344084998  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "ANNOTATIONS_FILE = \"annotations_file_short_SF.csv\"\n",
    "DATASET_DIR = '/workdir/sf_pv/data_v2'\n",
    "PATH2DATASET = \"/workdir/sf_pv\"\n",
    "\n",
    "# Dataset\n",
    "train_dataset = SpeakingFacesDataset(ANNOTATIONS_FILE,DATASET_DIR,'train',\n",
    "                                    image_transform=T.image_transform, \n",
    "                                    audio_transform=T.audio_transform)\n",
    "valid_dataset = ValidDataset(PATH2DATASET,'valid',\n",
    "                        image_transform=T.image_transform, \n",
    "                        audio_transform=T.audio_transform)\n",
    "\n",
    "# sampler\n",
    "train_sampler = ProtoSampler(train_dataset.labels,\n",
    "                            n_batch=200,\n",
    "                            n_ways=60, # n_way\n",
    "                            n_support=1, # n_shots\n",
    "                            n_query=1)\n",
    "\n",
    "# dataloader\n",
    "train_dataloader = DataLoader(dataset=train_dataset, \n",
    "                        batch_sampler=train_sampler,\n",
    "                        num_workers=4, pin_memory=True\n",
    "                        )\n",
    "\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        num_workers=4, \n",
    "                        pin_memory=True)\n",
    "\n",
    "# optimizer + scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay = 0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.5, last_epoch=-1)\n",
    "\n",
    "# loss\n",
    "criterion = PrototypicalLoss(dist_type='cosine_similarity')\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# train\n",
    "model = train_model(model,\n",
    "                    train_dataloader, \n",
    "                    valid_dataloader,\n",
    "                    train_sampler,\n",
    "                    criterion,\n",
    "                    optimizer,\n",
    "                    scheduler,\n",
    "                    device,\n",
    "                    num_epochs=1,\n",
    "                    save_dir=\"/workdir/Speaker_Verification_version_1.0/results\",\n",
    "                    exp_name=\"chern\",\n",
    "                    modality=\"rgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet2 (from timm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('resnet34', pretrained=True, num_classes=128, in_chans=3)\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unfrozen parameters with fine_tune=True: 21350336/21350336 - 100.0 %\n",
      "Number of frozen parameters with fine_tune=True: 0/21350336 - 0.0 %\n",
      "Total number of parameters with fine_tune=True: 21350336\n"
     ]
    }
   ],
   "source": [
    "unfrozen = 0\n",
    "frozen = 0\n",
    "total = 0\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad:\n",
    "        unfrozen += param.numel()\n",
    "    else:\n",
    "        frozen += param.numel()\n",
    "    total += param.numel()\n",
    "\n",
    "print(f\"Number of unfrozen parameters with fine_tune=True: {unfrozen}/{total} - {unfrozen/total * 100} %\")\n",
    "print(f\"Number of frozen parameters with fine_tune=True: {frozen}/{total} - {frozen / total * 100} %\")\n",
    "print(f\"Total number of parameters with fine_tune=True: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.get_classifier().weight.requires_grad = True\n",
    "model.get_classifier().bias.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unfrozen parameters with fine_tune=True: 65664/21350336 - 0.307554878761627 %\n",
      "Number of frozen parameters with fine_tune=True: 21284672/21350336 - 99.69244512123836 %\n",
      "Total number of parameters with fine_tune=True: 21350336\n"
     ]
    }
   ],
   "source": [
    "unfrozen = 0\n",
    "frozen = 0\n",
    "total = 0\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad:\n",
    "        unfrozen += param.numel()\n",
    "    else:\n",
    "        frozen += param.numel()\n",
    "    total += param.numel()\n",
    "\n",
    "print(f\"Number of unfrozen parameters with fine_tune=False: {unfrozen}/{total} - {unfrozen/total * 100} %\")\n",
    "print(f\"Number of frozen parameters with fine_tune=False: {frozen}/{total} - {frozen / total * 100} %\")\n",
    "print(f\"Total number of parameters with fine_tune=False: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average train loss: 4.09741884469986\n",
      "Average train accuracy: 1.8833334314823151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval (epoch = 0): 100%|██████████| 594/594 [01:17<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average val eer: 49.467722624598146\n",
      "\n",
      "Average val accuracy: 50.57519640852974\n",
      "Best eer model saved at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [01:48<00:00, 108.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best acc model saved at epoch 0\n",
      "Time elapsed: 1.8148329654708504  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "ANNOTATIONS_FILE = \"annotations_file_short_SF.csv\"\n",
    "DATASET_DIR = '/workdir/sf_pv/data_v2'\n",
    "PATH2DATASET = \"/workdir/sf_pv\"\n",
    "\n",
    "# Dataset\n",
    "train_dataset = SpeakingFacesDataset(ANNOTATIONS_FILE,DATASET_DIR,'train',\n",
    "                                    image_transform=T.image_transform, \n",
    "                                    audio_transform=T.audio_transform)\n",
    "valid_dataset = ValidDataset(PATH2DATASET,'valid',\n",
    "                        image_transform=T.image_transform, \n",
    "                        audio_transform=T.audio_transform)\n",
    "\n",
    "# sampler\n",
    "train_sampler = ProtoSampler(train_dataset.labels,\n",
    "                            n_batch=200,\n",
    "                            n_ways=60, # n_way\n",
    "                            n_support=1, # n_shots\n",
    "                            n_query=1)\n",
    "\n",
    "# dataloader\n",
    "train_dataloader = DataLoader(dataset=train_dataset, \n",
    "                        batch_sampler=train_sampler,\n",
    "                        num_workers=4, pin_memory=True\n",
    "                        )\n",
    "\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        num_workers=4, \n",
    "                        pin_memory=True)\n",
    "\n",
    "# optimizer + scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay = 0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.5, last_epoch=-1)\n",
    "\n",
    "# loss\n",
    "criterion = PrototypicalLoss(dist_type='cosine_similarity')\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# train\n",
    "model = train_model(model,\n",
    "                    train_dataloader, \n",
    "                    valid_dataloader,\n",
    "                    train_sampler,\n",
    "                    criterion,\n",
    "                    optimizer,\n",
    "                    scheduler,\n",
    "                    device,\n",
    "                    num_epochs=1,\n",
    "                    save_dir=\"/workdir/Speaker_Verification_version_1.0/results\",\n",
    "                    exp_name=\"chern\",\n",
    "                    modality=\"rgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speaker_verification.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(model):\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # dataset\n",
    "    ANNOTATIONS_FILE = \"annotations_file_short_SF.csv\"\n",
    "    DATASET_DIR = '/workdir/sf_pv/data_v2'\n",
    "    PATH2DATASET = \"/workdir/sf_pv\"\n",
    "\n",
    "    # Dataset\n",
    "    train_dataset = SpeakingFacesDataset(ANNOTATIONS_FILE,DATASET_DIR,'train',\n",
    "                                        image_transform=T.image_transform, \n",
    "                                        audio_transform=T.audio_transform)\n",
    "    valid_dataset = ValidDataset(PATH2DATASET,'valid',\n",
    "                            image_transform=T.image_transform, \n",
    "                            audio_transform=T.audio_transform)\n",
    "\n",
    "    # sampler\n",
    "    train_sampler = ProtoSampler(train_dataset.labels,\n",
    "                                n_batch=50,\n",
    "                                n_ways=5, # n_way\n",
    "                                n_support=1, # n_shots\n",
    "                                n_query=1)\n",
    "\n",
    "    # dataloader\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, \n",
    "                            batch_sampler=train_sampler,\n",
    "                            num_workers=4, pin_memory=True\n",
    "                            )\n",
    "\n",
    "    valid_dataloader = DataLoader(dataset=valid_dataset,\n",
    "                            batch_size=64,\n",
    "                            shuffle=True,\n",
    "                            num_workers=4, \n",
    "                            pin_memory=True)\n",
    "\n",
    "    # optimizer + scheduler\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay = 0)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.5, last_epoch=-1)\n",
    "\n",
    "    # loss\n",
    "    criterion = PrototypicalLoss(dist_type='squared_euclidean')\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    # train\n",
    "    model = train_model(model,\n",
    "                        train_dataloader, \n",
    "                        valid_dataloader,\n",
    "                        train_sampler,\n",
    "                        criterion,\n",
    "                        optimizer,\n",
    "                        scheduler,\n",
    "                        device,\n",
    "                        num_epochs=1,\n",
    "                        save_dir=\"/workdir/Speaker_Verification_version_1.0/results\",\n",
    "                        exp_name=\"chern\",\n",
    "                        modality=\"rgb\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8245dd51eaea4205b4717a098086786e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50dd9e21ea4f4877b8cde69252cfa146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train (epoch = 0):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average train loss: 10.1061541390419\n",
      "Average train accuracy: 43.60000122070313\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2cec970a824b58b8a93e9f269aeaca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (epoch = 0):   0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average val eer: 35.600263328071065\n",
      "\n",
      "Average val accuracy: 64.3755260942761\n",
      "Best eer model saved at epoch 0\n",
      "Best acc model saved at epoch 0\n",
      "Time elapsed: 1.3073300561867653  minutes\n"
     ]
    }
   ],
   "source": [
    "model = Model(library=\"pytorch\", \n",
    "                pretrained_weights=True, \n",
    "                fine_tune=False, \n",
    "                embedding_size=128, \n",
    "                modality = \"rgb\",\n",
    "                model_name = \"resnet34\",\n",
    "                pool=\"default\")\n",
    "\n",
    "train_pipeline(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73871d66608416ca2ad41db13c7ebe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d852a102594f9cad07d33a955ffb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train (epoch = 0):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average train loss: 10.644466586387717\n",
      "Average train accuracy: 42.0000008392334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594f317704484ae18173a5ed6ff9b6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (epoch = 0):   0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average val eer: 33.319663053788055\n",
      "\n",
      "Average val accuracy: 66.67631172839506\n",
      "Best eer model saved at epoch 0\n",
      "Best acc model saved at epoch 0\n",
      "Time elapsed: 1.3062162003324678  minutes\n"
     ]
    }
   ],
   "source": [
    "model = Model(library=\"timm\", \n",
    "                pretrained_weights=True, \n",
    "                fine_tune=False, \n",
    "                embedding_size=128, \n",
    "                modality = \"rgb\",\n",
    "                model_name = \"resnet34\",\n",
    "                pool=\"default\")\n",
    "\n",
    "train_pipeline(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
